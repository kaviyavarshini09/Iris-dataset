# Iris-dataset
# Task 6 â€“ K-Nearest Neighbors (KNN) Classification
## ğŸ“ Internship Project: AI & ML â€“ KNN Implementation
This project involves implementing the K-Nearest Neighbors (KNN) classification algorithm using the **Iris dataset** from scikit-learn. The objective is to understand how KNN works, evaluate the model performance, experiment with different values of K, and visualize the decision boundaries.
---
## ğŸ“š What I Learned

- Instance-based (lazy) learning
- Euclidean distance metric
- Feature normalization
- Choosing the best K value
- Model evaluation using accuracy, confusion matrix
- Visualization with PCA
---
## ğŸ”§ Tools & Libraries Used
- Python
- Jupyter Notebook
- scikit-learn
- pandas
- numpy
- matplotlib
- seaborn
---
## ğŸ“Š Dataset
- **Name**: Iris Dataset
- **Source**: [scikit-learn built-in](https://www.kaggle.com/datasets/uciml/iris)
- **Features**:
  - sepal length
  - sepal width
  - petal length
  - petal width
- **Classes**: 
  - Setosa
  - Versicolor
  - Virginica
---
## ğŸ“ˆ Steps Performed
1. **Loaded Dataset**
2. **Normalized Features** using `StandardScaler`
3. **Split Data** into training and testing sets
4. **Trained KNN model** using different K values
5. **Evaluated Model** using:
   - Accuracy Score
   - Confusion Matrix
   - Classification Report
6. **Visualized** PCA plot for decision boundaries
---

## ğŸ“Œ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/knn-classification-task6.git
   cd knn-classification-task6
